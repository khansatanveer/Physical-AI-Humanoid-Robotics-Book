"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[8507],{3488:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"module-3-digital-twin/chapter-3-exercises","title":"Chapter 3: Sensor Simulation and Integration - Exercises","description":"Exercise 3.1: LiDAR Sensor Implementation","source":"@site/docs/module-3-digital-twin/chapter-3-exercises.md","sourceDirName":"module-3-digital-twin","slug":"/module-3-digital-twin/chapter-3-exercises","permalink":"/docs/module-3-digital-twin/chapter-3-exercises","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-humanoid-robotics-book/physical-ai-humanoid-robotics-book/tree/main/Physical-AI-Humanoid-Robotics-book/docs/docs/module-3-digital-twin/chapter-3-exercises.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 3: Sensor Simulation and Integration","permalink":"/docs/module-3-digital-twin/chapter-3-sensor-simulation"},"next":{"title":"Gazebo-Unity Integration Workflow","permalink":"/docs/module-3-digital-twin/workflow-sketch"}}');var t=n(4848),l=n(8453);const r={},a="Chapter 3: Sensor Simulation and Integration - Exercises",o={},d=[{value:"Exercise 3.1: LiDAR Sensor Implementation",id:"exercise-31-lidar-sensor-implementation",level:2},{value:"Objective",id:"objective",level:3},{value:"Tasks",id:"tasks",level:3},{value:"Implementation Steps",id:"implementation-steps",level:3},{value:"Validation Criteria",id:"validation-criteria",level:3},{value:"Submission Requirements",id:"submission-requirements",level:3},{value:"Exercise 3.2: Depth Camera Integration",id:"exercise-32-depth-camera-integration",level:2},{value:"Objective",id:"objective-1",level:3},{value:"Tasks",id:"tasks-1",level:3},{value:"Implementation Steps",id:"implementation-steps-1",level:3},{value:"Validation Criteria",id:"validation-criteria-1",level:3},{value:"Submission Requirements",id:"submission-requirements-1",level:3},{value:"Exercise 3.3: IMU Sensor Configuration",id:"exercise-33-imu-sensor-configuration",level:2},{value:"Objective",id:"objective-2",level:3},{value:"Tasks",id:"tasks-2",level:3},{value:"Implementation Steps",id:"implementation-steps-2",level:3},{value:"Validation Criteria",id:"validation-criteria-2",level:3},{value:"Submission Requirements",id:"submission-requirements-2",level:3},{value:"Exercise 3.4: Sensor Data Processing Pipeline",id:"exercise-34-sensor-data-processing-pipeline",level:2},{value:"Objective",id:"objective-3",level:3},{value:"Tasks",id:"tasks-3",level:3},{value:"Implementation Steps",id:"implementation-steps-3",level:3},{value:"Validation Criteria",id:"validation-criteria-3",level:3},{value:"Submission Requirements",id:"submission-requirements-3",level:3},{value:"Exercise 3.5: Unity Sensor Visualization",id:"exercise-35-unity-sensor-visualization",level:2},{value:"Objective",id:"objective-4",level:3},{value:"Tasks",id:"tasks-4",level:3},{value:"Implementation Steps",id:"implementation-steps-4",level:3},{value:"Validation Criteria",id:"validation-criteria-4",level:3},{value:"Submission Requirements",id:"submission-requirements-4",level:3},{value:"Exercise 3.6: Multi-Sensor Integration Challenge",id:"exercise-36-multi-sensor-integration-challenge",level:2},{value:"Objective",id:"objective-5",level:3},{value:"Tasks",id:"tasks-5",level:3},{value:"Implementation Steps",id:"implementation-steps-5",level:3},{value:"Validation Criteria",id:"validation-criteria-5",level:3},{value:"Submission Requirements",id:"submission-requirements-5",level:3},{value:"Assessment Rubric",id:"assessment-rubric",level:2},{value:"Technical Implementation (50%)",id:"technical-implementation-50",level:3},{value:"Data Processing (25%)",id:"data-processing-25",level:3},{value:"Integration and Validation (25%)",id:"integration-and-validation-25",level:3},{value:"Additional Challenge (Bonus 10%)",id:"additional-challenge-bonus-10",level:3}];function c(e){const i={h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",ul:"ul",...(0,l.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(i.header,{children:(0,t.jsx)(i.h1,{id:"chapter-3-sensor-simulation-and-integration---exercises",children:"Chapter 3: Sensor Simulation and Integration - Exercises"})}),"\n",(0,t.jsx)(i.h2,{id:"exercise-31-lidar-sensor-implementation",children:"Exercise 3.1: LiDAR Sensor Implementation"}),"\n",(0,t.jsx)(i.h3,{id:"objective",children:"Objective"}),"\n",(0,t.jsx)(i.p,{children:"Implement a LiDAR sensor on your humanoid robot model and verify its functionality in Gazebo simulation."}),"\n",(0,t.jsx)(i.h3,{id:"tasks",children:"Tasks"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsx)(i.li,{children:"Add a LiDAR sensor to your robot's URDF model"}),"\n",(0,t.jsx)(i.li,{children:"Configure the sensor with appropriate parameters for your application"}),"\n",(0,t.jsx)(i.li,{children:"Test that the sensor publishes LaserScan messages in ROS"}),"\n",(0,t.jsx)(i.li,{children:"Visualize the LiDAR data to confirm proper operation"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"implementation-steps",children:"Implementation Steps"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsx)(i.li,{children:"Define a new link for the LiDAR sensor in your URDF"}),"\n",(0,t.jsx)(i.li,{children:"Add a fixed joint connecting the LiDAR to an appropriate link (e.g., head or torso)"}),"\n",(0,t.jsxs)(i.li,{children:["Configure the Gazebo plugin with realistic parameters:","\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Set update rate to 10Hz"}),"\n",(0,t.jsx)(i.li,{children:"Configure 360-degree horizontal scan with 1-degree resolution"}),"\n",(0,t.jsx)(i.li,{children:"Set range from 0.1m to 30m"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(i.li,{children:"Launch the simulation and verify sensor data publication"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"validation-criteria",children:"Validation Criteria"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"LiDAR sensor appears in the Gazebo model"}),"\n",(0,t.jsx)(i.li,{children:"LaserScan messages are published at the configured rate"}),"\n",(0,t.jsx)(i.li,{children:"Range values are within expected parameters"}),"\n",(0,t.jsx)(i.li,{children:"Sensor data is free of artifacts or invalid readings"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"submission-requirements",children:"Submission Requirements"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"URDF code snippet showing the LiDAR sensor definition"}),"\n",(0,t.jsx)(i.li,{children:"Console output showing active LiDAR topic"}),"\n",(0,t.jsx)(i.li,{children:"Screenshot of LiDAR visualization in Gazebo (if available)"}),"\n",(0,t.jsx)(i.li,{children:"Description of how you validated the sensor's proper operation"}),"\n"]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"exercise-32-depth-camera-integration",children:"Exercise 3.2: Depth Camera Integration"}),"\n",(0,t.jsx)(i.h3,{id:"objective-1",children:"Objective"}),"\n",(0,t.jsx)(i.p,{children:"Add a depth camera to your robot and configure it to publish both color and depth images."}),"\n",(0,t.jsx)(i.h3,{id:"tasks-1",children:"Tasks"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsx)(i.li,{children:"Add a depth camera sensor to your robot's URDF model"}),"\n",(0,t.jsx)(i.li,{children:"Configure camera parameters for your application"}),"\n",(0,t.jsx)(i.li,{children:"Verify that both color and depth images are published"}),"\n",(0,t.jsx)(i.li,{children:"Process the depth images to extract meaningful information"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"implementation-steps-1",children:"Implementation Steps"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsx)(i.li,{children:"Create a camera link and attach it to your robot (e.g., head)"}),"\n",(0,t.jsxs)(i.li,{children:["Configure the depth camera plugin with:","\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"640x480 resolution"}),"\n",(0,t.jsx)(i.li,{children:"60-degree horizontal field of view"}),"\n",(0,t.jsx)(i.li,{children:"30Hz update rate"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(i.li,{children:"Launch the simulation and monitor both image topics"}),"\n",(0,t.jsx)(i.li,{children:"Write a simple ROS node to process the depth images"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"validation-criteria-1",children:"Validation Criteria"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Camera publishes color images (sensor_msgs/Image)"}),"\n",(0,t.jsx)(i.li,{children:"Camera publishes depth images (sensor_msgs/Image with 32FC1 encoding)"}),"\n",(0,t.jsx)(i.li,{children:"Depth values are in meters and within expected range"}),"\n",(0,t.jsx)(i.li,{children:"Images are free of distortion or artifacts"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"submission-requirements-1",children:"Submission Requirements"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"URDF code snippet for the depth camera"}),"\n",(0,t.jsx)(i.li,{children:"Output showing both image topics are active"}),"\n",(0,t.jsx)(i.li,{children:"Python code for a simple depth processing node"}),"\n",(0,t.jsx)(i.li,{children:"Sample processed depth data with explanation"}),"\n"]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"exercise-33-imu-sensor-configuration",children:"Exercise 3.3: IMU Sensor Configuration"}),"\n",(0,t.jsx)(i.h3,{id:"objective-2",children:"Objective"}),"\n",(0,t.jsx)(i.p,{children:"Implement an IMU sensor on your robot to provide orientation and acceleration data."}),"\n",(0,t.jsx)(i.h3,{id:"tasks-2",children:"Tasks"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsx)(i.li,{children:"Add an IMU sensor to your robot's URDF model"}),"\n",(0,t.jsx)(i.li,{children:"Configure realistic noise parameters"}),"\n",(0,t.jsx)(i.li,{children:"Verify IMU data publication and quality"}),"\n",(0,t.jsx)(i.li,{children:"Process IMU data to extract orientation information"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"implementation-steps-2",children:"Implementation Steps"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsx)(i.li,{children:"Define an IMU link in your robot's torso (for best motion tracking)"}),"\n",(0,t.jsxs)(i.li,{children:["Configure the IMU plugin with realistic noise values:","\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Angular velocity noise: 2e-4 rad/s stddev"}),"\n",(0,t.jsx)(i.li,{children:"Linear acceleration noise: 1.7e-2 m/s\xb2 stddev"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(i.li,{children:"Set update rate to 100Hz for responsive orientation tracking"}),"\n",(0,t.jsx)(i.li,{children:"Create a ROS node to process and validate IMU data"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"validation-criteria-2",children:"Validation Criteria"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"IMU publishes sensor_msgs/Imu messages at 100Hz"}),"\n",(0,t.jsx)(i.li,{children:"Orientation quaternion represents valid rotation"}),"\n",(0,t.jsx)(i.li,{children:"Angular velocity and linear acceleration are reasonable"}),"\n",(0,t.jsx)(i.li,{children:"Noise parameters produce realistic sensor behavior"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"submission-requirements-2",children:"Submission Requirements"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"URDF code snippet for the IMU sensor"}),"\n",(0,t.jsx)(i.li,{children:"Sample IMU messages showing all fields"}),"\n",(0,t.jsx)(i.li,{children:"Python code for IMU processing and validation"}),"\n",(0,t.jsx)(i.li,{children:"Analysis of noise characteristics in the sensor data"}),"\n"]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"exercise-34-sensor-data-processing-pipeline",children:"Exercise 3.4: Sensor Data Processing Pipeline"}),"\n",(0,t.jsx)(i.h3,{id:"objective-3",children:"Objective"}),"\n",(0,t.jsx)(i.p,{children:"Create a comprehensive sensor processing pipeline that handles data from all sensor types."}),"\n",(0,t.jsx)(i.h3,{id:"tasks-3",children:"Tasks"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsx)(i.li,{children:"Implement a ROS node that subscribes to all sensor topics"}),"\n",(0,t.jsx)(i.li,{children:"Process and validate data from each sensor type"}),"\n",(0,t.jsx)(i.li,{children:"Implement basic sensor fusion techniques"}),"\n",(0,t.jsx)(i.li,{children:"Create visualization for processed sensor data"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"implementation-steps-3",children:"Implementation Steps"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsxs)(i.li,{children:["Create a ROS node with subscribers for:","\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"/basic_humanoid/scan (LiDAR)"}),"\n",(0,t.jsx)(i.li,{children:"/basic_humanoid/camera/image_raw (Color camera)"}),"\n",(0,t.jsx)(i.li,{children:"/basic_humanoid/camera/depth/image_raw (Depth camera)"}),"\n",(0,t.jsx)(i.li,{children:"/basic_humanoid/imu (IMU)"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(i.li,{children:"Implement data validation and preprocessing"}),"\n",(0,t.jsx)(i.li,{children:"Create simple obstacle detection using LiDAR data"}),"\n",(0,t.jsx)(i.li,{children:"Implement basic sensor fusion for position estimation"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"validation-criteria-3",children:"Validation Criteria"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Node processes all sensor data without errors"}),"\n",(0,t.jsx)(i.li,{children:"Processing maintains real-time performance"}),"\n",(0,t.jsx)(i.li,{children:"Obstacle detection works with LiDAR data"}),"\n",(0,t.jsx)(i.li,{children:"Sensor fusion improves position estimation accuracy"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"submission-requirements-3",children:"Submission Requirements"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Complete ROS node implementation"}),"\n",(0,t.jsx)(i.li,{children:"Performance metrics (processing time, CPU usage)"}),"\n",(0,t.jsx)(i.li,{children:"Test results showing obstacle detection"}),"\n",(0,t.jsx)(i.li,{children:"Comparison of fused vs individual sensor data"}),"\n"]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"exercise-35-unity-sensor-visualization",children:"Exercise 3.5: Unity Sensor Visualization"}),"\n",(0,t.jsx)(i.h3,{id:"objective-4",children:"Objective"}),"\n",(0,t.jsx)(i.p,{children:"Implement visualization of sensor data in the Unity digital twin environment."}),"\n",(0,t.jsx)(i.h3,{id:"tasks-4",children:"Tasks"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsx)(i.li,{children:"Create Unity components to visualize LiDAR point clouds"}),"\n",(0,t.jsx)(i.li,{children:"Implement depth camera point cloud visualization"}),"\n",(0,t.jsx)(i.li,{children:"Visualize IMU orientation in the Unity scene"}),"\n",(0,t.jsx)(i.li,{children:"Integrate sensor visualization with the digital twin"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"implementation-steps-4",children:"Implementation Steps"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsx)(i.li,{children:"Create a SensorVisualization script in Unity"}),"\n",(0,t.jsx)(i.li,{children:"Implement LiDAR point visualization using the LaserScan data"}),"\n",(0,t.jsx)(i.li,{children:"Add depth camera point cloud visualization"}),"\n",(0,t.jsx)(i.li,{children:"Create IMU orientation indicator"}),"\n",(0,t.jsx)(i.li,{children:"Connect Unity visualization to ROS sensor data"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"validation-criteria-4",children:"Validation Criteria"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"LiDAR points appear correctly in Unity scene"}),"\n",(0,t.jsx)(i.li,{children:"Depth camera data visualizes as 3D point cloud"}),"\n",(0,t.jsx)(i.li,{children:"IMU orientation indicator shows correct rotation"}),"\n",(0,t.jsx)(i.li,{children:"Sensor visualization updates in real-time"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"submission-requirements-4",children:"Submission Requirements"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Unity C# script for sensor visualization"}),"\n",(0,t.jsx)(i.li,{children:"Screenshot showing sensor visualizations in Unity"}),"\n",(0,t.jsx)(i.li,{children:"Description of how sensor data is transmitted to Unity"}),"\n",(0,t.jsx)(i.li,{children:"Performance metrics for visualization system"}),"\n"]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"exercise-36-multi-sensor-integration-challenge",children:"Exercise 3.6: Multi-Sensor Integration Challenge"}),"\n",(0,t.jsx)(i.h3,{id:"objective-5",children:"Objective"}),"\n",(0,t.jsx)(i.p,{children:"Integrate all sensor systems into a cohesive perception system for the digital twin."}),"\n",(0,t.jsx)(i.h3,{id:"tasks-5",children:"Tasks"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsx)(i.li,{children:"Combine data from all three sensor types"}),"\n",(0,t.jsx)(i.li,{children:"Implement a sensor fusion algorithm"}),"\n",(0,t.jsx)(i.li,{children:"Create a unified perception output"}),"\n",(0,t.jsx)(i.li,{children:"Validate the integrated system performance"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"implementation-steps-5",children:"Implementation Steps"}),"\n",(0,t.jsxs)(i.ol,{children:["\n",(0,t.jsx)(i.li,{children:"Extend your ROS sensor processing node to combine all sensor data"}),"\n",(0,t.jsx)(i.li,{children:"Implement a simple sensor fusion approach (e.g., weighted average or complementary filter)"}),"\n",(0,t.jsx)(i.li,{children:"Create a unified output topic with fused sensor state"}),"\n",(0,t.jsx)(i.li,{children:"Test the integrated system in various simulated environments"}),"\n",(0,t.jsx)(i.li,{children:"Validate that the fused data is more accurate than individual sensors"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"validation-criteria-5",children:"Validation Criteria"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"All sensors contribute to the fused output"}),"\n",(0,t.jsx)(i.li,{children:"Fused data is more robust than individual sensors"}),"\n",(0,t.jsx)(i.li,{children:"System maintains real-time performance with all sensors active"}),"\n",(0,t.jsx)(i.li,{children:"Integration handles sensor failures gracefully"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"submission-requirements-5",children:"Submission Requirements"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Complete multi-sensor fusion implementation"}),"\n",(0,t.jsx)(i.li,{children:"Comparison of fused vs individual sensor performance"}),"\n",(0,t.jsx)(i.li,{children:"Test results in different simulated scenarios"}),"\n",(0,t.jsx)(i.li,{children:"Analysis of fusion algorithm effectiveness"}),"\n"]}),"\n",(0,t.jsx)(i.hr,{}),"\n",(0,t.jsx)(i.h2,{id:"assessment-rubric",children:"Assessment Rubric"}),"\n",(0,t.jsx)(i.h3,{id:"technical-implementation-50",children:"Technical Implementation (50%)"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Correct implementation of all sensor types"}),"\n",(0,t.jsx)(i.li,{children:"Proper ROS topic configuration and message handling"}),"\n",(0,t.jsx)(i.li,{children:"Accurate sensor modeling with realistic parameters"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"data-processing-25",children:"Data Processing (25%)"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Effective processing and validation of sensor data"}),"\n",(0,t.jsx)(i.li,{children:"Implementation of sensor fusion techniques"}),"\n",(0,t.jsx)(i.li,{children:"Real-time performance maintenance"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"integration-and-validation-25",children:"Integration and Validation (25%)"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"Successful integration of all sensor systems"}),"\n",(0,t.jsx)(i.li,{children:"Proper validation of sensor functionality"}),"\n",(0,t.jsx)(i.li,{children:"Comprehensive testing and documentation"}),"\n"]}),"\n",(0,t.jsx)(i.h3,{id:"additional-challenge-bonus-10",children:"Additional Challenge (Bonus 10%)"}),"\n",(0,t.jsx)(i.p,{children:"Implement advanced features such as:"}),"\n",(0,t.jsxs)(i.ul,{children:["\n",(0,t.jsx)(i.li,{children:"SLAM (Simultaneous Localization and Mapping) using LiDAR data"}),"\n",(0,t.jsx)(i.li,{children:"Object detection and classification using camera data"}),"\n",(0,t.jsx)(i.li,{children:"Predictive sensor fusion using Kalman filters"}),"\n",(0,t.jsx)(i.li,{children:"Advanced visualization techniques for sensor data"}),"\n"]})]})}function h(e={}){const{wrapper:i}={...(0,l.R)(),...e.components};return i?(0,t.jsx)(i,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,i,n)=>{n.d(i,{R:()=>r,x:()=>a});var s=n(6540);const t={},l=s.createContext(t);function r(e){const i=s.useContext(l);return s.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function a(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:r(e.components),s.createElement(l.Provider,{value:i},e.children)}}}]);