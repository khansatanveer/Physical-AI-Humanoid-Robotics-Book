"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_book=globalThis.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[9261],{4100:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-3-digital-twin/chapter-2-unity-visualization","title":"Chapter 2: Unity Environment Building and Visualization","description":"Learning Objectives","source":"@site/docs/module-3-digital-twin/chapter-2-unity-visualization.md","sourceDirName":"module-3-digital-twin","slug":"/module-3-digital-twin/chapter-2-unity-visualization","permalink":"/docs/module-3-digital-twin/chapter-2-unity-visualization","draft":false,"unlisted":false,"editUrl":"https://github.com/physical-ai-humanoid-robotics-book/physical-ai-humanoid-robotics-book/tree/main/Physical-AI-Humanoid-Robotics-book/docs/docs/module-3-digital-twin/chapter-2-unity-visualization.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: Physics Fundamentals Exercises","permalink":"/docs/module-3-digital-twin/chapter-1-exercises"},"next":{"title":"Chapter 2: Unity Environment Building and Visualization - Exercises","permalink":"/docs/module-3-digital-twin/chapter-2-exercises"}}');var o=i(4848),s=i(8453);const r={},a="Chapter 2: Unity Environment Building and Visualization",l={},c=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Setting Up Unity for Digital Twin Applications",id:"setting-up-unity-for-digital-twin-applications",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Unity Project Structure for Digital Twins",id:"unity-project-structure-for-digital-twins",level:3},{value:"Exercise 1: Basic Unity Scene Setup",id:"exercise-1-basic-unity-scene-setup",level:2},{value:"Step 1: Create New Unity Project",id:"step-1-create-new-unity-project",level:3},{value:"Step 2: Configure Project Settings",id:"step-2-configure-project-settings",level:3},{value:"Step 3: Basic Scene Setup",id:"step-3-basic-scene-setup",level:3},{value:"Exercise 2: Creating Environment Assets",id:"exercise-2-creating-environment-assets",level:2},{value:"Step 1: Ground Plane and Basic Obstacles",id:"step-1-ground-plane-and-basic-obstacles",level:3},{value:"Step 2: Coordinate System Alignment",id:"step-2-coordinate-system-alignment",level:3},{value:"Exercise 3: Robot Visualization Model",id:"exercise-3-robot-visualization-model",level:2},{value:"Step 1: Import Robot Model",id:"step-1-import-robot-model",level:3},{value:"Step 2: Robot Joint Visualization",id:"step-2-robot-joint-visualization",level:3},{value:"Exercise 4: Real-time Synchronization",id:"exercise-4-real-time-synchronization",level:2},{value:"Step 1: ROS Integration Setup",id:"step-1-ros-integration-setup",level:3},{value:"Step 2: Synchronization Pipeline",id:"step-2-synchronization-pipeline",level:3},{value:"Exercise 5: Performance Optimization",id:"exercise-5-performance-optimization",level:2},{value:"Optimization Techniques",id:"optimization-techniques",level:3},{value:"Exercise 6: Interactive Elements",id:"exercise-6-interactive-elements",level:2},{value:"Adding Interaction",id:"adding-interaction",level:3},{value:"Validation: Testing Your Unity Visualization",id:"validation-testing-your-unity-visualization",level:2},{value:"Troubleshooting Common Unity Issues",id:"troubleshooting-common-unity-issues",level:2},{value:"Visualization Doesn&#39;t Match Physics",id:"visualization-doesnt-match-physics",level:3},{value:"Poor Performance",id:"poor-performance",level:3},{value:"Synchronization Problems",id:"synchronization-problems",level:3},{value:"Summary",id:"summary",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"chapter-2-unity-environment-building-and-visualization",children:"Chapter 2: Unity Environment Building and Visualization"})}),"\n",(0,o.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,o.jsx)(n.p,{children:"After completing this chapter, you will be able to:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Set up a Unity project for digital twin visualization"}),"\n",(0,o.jsx)(n.li,{children:"Create interactive 3D environments that complement Gazebo physics"}),"\n",(0,o.jsx)(n.li,{children:"Build compelling visual representations of digital twins"}),"\n",(0,o.jsx)(n.li,{children:"Implement real-time synchronization between Gazebo and Unity"}),"\n",(0,o.jsx)(n.li,{children:"Validate that visualization meets performance targets (< 100ms response time)"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,o.jsx)(n.p,{children:"In the previous chapter, we established the physics foundation of our digital twin using Gazebo. Now, we'll focus on the visualization aspect using Unity, one of the most powerful real-time 3D engines available. A complete digital twin combines accurate physics simulation (Gazebo) with compelling visual representation (Unity) to mirror real-world robot behavior."}),"\n",(0,o.jsx)(n.p,{children:"Unity provides high-quality rendering, intuitive development tools, and excellent performance for real-time visualization. For digital twins, Unity handles the visual aspects - how the robot and environment appear, how users interact with the simulation, and how sensor data is visualized."}),"\n",(0,o.jsx)(n.h2,{id:"setting-up-unity-for-digital-twin-applications",children:"Setting Up Unity for Digital Twin Applications"}),"\n",(0,o.jsx)(n.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsx)(n.p,{children:"Before starting this chapter, ensure you have:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Unity 2023.2 LTS (Long Term Support) installed"}),"\n",(0,o.jsx)(n.li,{children:"Basic understanding of Unity concepts (scenes, GameObjects, components)"}),"\n",(0,o.jsx)(n.li,{children:"Completed Chapter 1 (Gazebo Physics Simulation)"}),"\n",(0,o.jsx)(n.li,{children:"ROS 2 and Gazebo installed for integration testing"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"unity-project-structure-for-digital-twins",children:"Unity Project Structure for Digital Twins"}),"\n",(0,o.jsx)(n.p,{children:"For digital twin applications, organize your Unity project as follows:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"Assets/\n\u251c\u2500\u2500 Scenes/              # Unity scene files for different environments\n\u251c\u2500\u2500 Models/              # 3D models for robots and environment\n\u251c\u2500\u2500 Materials/           # Material definitions for visual properties\n\u251c\u2500\u2500 Scripts/             # Custom scripts for integration and behavior\n\u251c\u2500\u2500 Plugins/             # External libraries for ROS integration\n\u251c\u2500\u2500 Resources/           # Runtime-loadable assets\n\u2514\u2500\u2500 Prefabs/             # Reusable GameObject templates\n"})}),"\n",(0,o.jsx)(n.h2,{id:"exercise-1-basic-unity-scene-setup",children:"Exercise 1: Basic Unity Scene Setup"}),"\n",(0,o.jsx)(n.p,{children:"Let's start by creating a basic Unity scene that will serve as the foundation for our digital twin visualization."}),"\n",(0,o.jsx)(n.h3,{id:"step-1-create-new-unity-project",children:"Step 1: Create New Unity Project"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Open Unity Hub"}),"\n",(0,o.jsx)(n.li,{children:'Click "New Project"'}),"\n",(0,o.jsx)(n.li,{children:'Select the "3D (Built-in Render Pipeline)" template'}),"\n",(0,o.jsx)(n.li,{children:'Name your project "DigitalTwinVisualization"'}),"\n",(0,o.jsx)(n.li,{children:"Choose a location to save the project"}),"\n",(0,o.jsx)(n.li,{children:'Click "Create Project"'}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"step-2-configure-project-settings",children:"Step 2: Configure Project Settings"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Go to Edit \u2192 Project Settings \u2192 Time"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Set Maximum Allowed Timestep to 0.333 (for 30 FPS minimum)"}),"\n",(0,o.jsx)(n.li,{children:"Set Fixed Timestep to 0.02 (50 FPS target for physics sync)"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"Go to Edit \u2192 Project Settings \u2192 Quality"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Adjust settings based on target hardware requirements"}),"\n",(0,o.jsx)(n.li,{children:"For digital twin applications, prioritize performance over visual quality"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"step-3-basic-scene-setup",children:"Step 3: Basic Scene Setup"}),"\n",(0,o.jsx)(n.p,{children:"Create a basic scene with:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Main Camera positioned for viewing the digital twin"}),"\n",(0,o.jsx)(n.li,{children:"Directional Light to match Gazebo's lighting"}),"\n",(0,o.jsx)(n.li,{children:"Basic plane for ground reference"}),"\n",(0,o.jsx)(n.li,{children:"UI elements for displaying simulation status"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-csharp",children:"// Example script to position camera for digital twin viewing\nusing UnityEngine;\n\npublic class DigitalTwinCamera : MonoBehaviour\n{\n    public Transform target; // The robot or object to focus on\n    public Vector3 offset = new Vector3(-5, 3, -5);\n    public float smoothSpeed = 0.125f;\n\n    void LateUpdate()\n    {\n        if (target != null)\n        {\n            Vector3 desiredPosition = target.position + offset;\n            Vector3 smoothedPosition = Vector3.Lerp(transform.position, desiredPosition, smoothSpeed);\n            transform.position = smoothedPosition;\n\n            transform.LookAt(target);\n        }\n    }\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"exercise-2-creating-environment-assets",children:"Exercise 2: Creating Environment Assets"}),"\n",(0,o.jsx)(n.p,{children:"Digital twins require accurate visual representation of the environment. Let's create some basic environment elements."}),"\n",(0,o.jsx)(n.h3,{id:"step-1-ground-plane-and-basic-obstacles",children:"Step 1: Ground Plane and Basic Obstacles"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Create a plane as the ground (GameObject \u2192 3D Object \u2192 Plane)"}),"\n",(0,o.jsx)(n.li,{children:"Add basic obstacles like cubes or cylinders to represent the Gazebo world"}),"\n",(0,o.jsx)(n.li,{children:"Apply materials that match the Gazebo environment for consistency"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"step-2-coordinate-system-alignment",children:"Step 2: Coordinate System Alignment"}),"\n",(0,o.jsx)(n.p,{children:"Unity and ROS/Gazebo use different coordinate systems:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"ROS/Gazebo"}),": X forward, Y left, Z up"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Unity"}),": X right, Y up, Z forward"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"This requires conversion when synchronizing positions between systems:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-csharp",children:"// Helper functions to convert between coordinate systems\npublic static class CoordinateConverter\n{\n    // Convert from ROS coordinate system to Unity\n    public static Vector3 RosToUnity(Vector3 rosVector)\n    {\n        return new Vector3(rosVector.z, rosVector.x, rosVector.y);\n    }\n\n    // Convert from Unity coordinate system to ROS\n    public static Vector3 UnityToRos(Vector3 unityVector)\n    {\n        return new Vector3(unityVector.y, unityVector.z, unityVector.x);\n    }\n\n    // Convert rotation from ROS to Unity\n    public static Quaternion RosToUnity(Quaternion rosQuaternion)\n    {\n        return new Quaternion(rosQuaternion.w, rosQuaternion.z, rosQuaternion.x, rosQuaternion.y);\n    }\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"exercise-3-robot-visualization-model",children:"Exercise 3: Robot Visualization Model"}),"\n",(0,o.jsx)(n.p,{children:"Now let's create a visualization model for our humanoid robot that matches the physics model from Chapter 1."}),"\n",(0,o.jsx)(n.h3,{id:"step-1-import-robot-model",children:"Step 1: Import Robot Model"}),"\n",(0,o.jsx)(n.p,{children:"For digital twins, the visual model should match the physical model as closely as possible:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"Create primitive shapes (cylinders, spheres, boxes) that match the URDF dimensions"}),"\n",(0,o.jsx)(n.li,{children:"Position and scale them according to the URDF specifications"}),"\n",(0,o.jsx)(n.li,{children:"Apply appropriate materials and colors"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"step-2-robot-joint-visualization",children:"Step 2: Robot Joint Visualization"}),"\n",(0,o.jsx)(n.p,{children:"Create a hierarchy that matches the URDF joint structure:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["Base link (body)","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Head"}),"\n",(0,o.jsxs)(n.li,{children:["Left arm (with sub-joints)","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Upper arm"}),"\n",(0,o.jsx)(n.li,{children:"Lower arm"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["Right arm (with sub-joints)","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Upper arm"}),"\n",(0,o.jsx)(n.li,{children:"Lower arm"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["Left leg (with sub-joints)","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Upper leg"}),"\n",(0,o.jsx)(n.li,{children:"Lower leg"}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["Right leg (with sub-joints)","\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Upper leg"}),"\n",(0,o.jsx)(n.li,{children:"Lower leg"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-csharp",children:"// Robot controller script to synchronize joint positions\nusing UnityEngine;\n\npublic class RobotController : MonoBehaviour\n{\n    [System.Serializable]\n    public class JointInfo\n    {\n        public string jointName;\n        public Transform jointTransform;\n        public float position; // Current joint position\n        public float minLimit = -1.57f;\n        public float maxLimit = 1.57f;\n    }\n\n    public JointInfo[] joints;\n\n    // Update joint positions based on ROS messages\n    public void UpdateJointPositions(float[] jointPositions)\n    {\n        for (int i = 0; i < Mathf.Min(joints.Length, jointPositions.Length); i++)\n        {\n            float clampedPosition = Mathf.Clamp(jointPositions[i], joints[i].minLimit, joints[i].maxLimit);\n            joints[i].position = clampedPosition;\n\n            // Apply rotation based on joint type (simplified for revolute joints)\n            if (joints[i].jointTransform != null)\n            {\n                joints[i].jointTransform.localRotation = Quaternion.Euler(0, 0, clampedPosition * Mathf.Rad2Deg);\n            }\n        }\n    }\n}\n"})}),"\n",(0,o.jsx)(n.h2,{id:"exercise-4-real-time-synchronization",children:"Exercise 4: Real-time Synchronization"}),"\n",(0,o.jsx)(n.p,{children:"The core of a digital twin is real-time synchronization between physics simulation and visualization."}),"\n",(0,o.jsx)(n.h3,{id:"step-1-ros-integration-setup",children:"Step 1: ROS Integration Setup"}),"\n",(0,o.jsx)(n.p,{children:"To connect Unity with ROS, you'll typically use:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"ROS# (ROS bridge for Unity) - Unity package for ROS communication"}),"\n",(0,o.jsx)(n.li,{children:"WebSocket connections to rosbridge_suite"}),"\n",(0,o.jsx)(n.li,{children:"Custom integration layer"}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-csharp",children:'// Example of a basic ROS connection script\nusing UnityEngine;\nusing RosSharp.RosBridgeClient;\n\npublic class DigitalTwinConnector : MonoBehaviour\n{\n    public string rosBridgeServerUrl = "ws://localhost:9090";\n    private RosSocket rosSocket;\n\n    void Start()\n    {\n        ConnectToRosBridge();\n    }\n\n    void ConnectToRosBridge()\n    {\n        RosBridgeClient.Protocols.WebSocketNetProtocol webSocket =\n            new RosBridgeClient.Protocols.WebSocketNetProtocol(rosBridgeServerUrl);\n\n        rosSocket = new RosSocket(webSocket);\n\n        // Subscribe to robot state topic\n        rosSocket.Subscribe<sensor_msgs.JointState>(\n            "/basic_humanoid/joint_states",\n            UpdateRobotJoints);\n    }\n\n    void UpdateRobotJoints(sensor_msgs.JointState jointState)\n    {\n        // Update Unity visualization based on ROS joint states\n        // This method should update the RobotController with new positions\n    }\n\n    void OnDestroy()\n    {\n        rosSocket?.Close();\n    }\n}\n'})}),"\n",(0,o.jsx)(n.h3,{id:"step-2-synchronization-pipeline",children:"Step 2: Synchronization Pipeline"}),"\n",(0,o.jsx)(n.p,{children:"Create a pipeline for real-time synchronization:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsx)(n.li,{children:"ROS publishes joint states at high frequency (50Hz+)"}),"\n",(0,o.jsx)(n.li,{children:"Unity receives and processes these messages"}),"\n",(0,o.jsx)(n.li,{children:"Robot visualization updates in real-time"}),"\n",(0,o.jsx)(n.li,{children:"Performance is maintained above 30 FPS"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"exercise-5-performance-optimization",children:"Exercise 5: Performance Optimization"}),"\n",(0,o.jsx)(n.p,{children:"For digital twin applications, maintaining performance is crucial. Unity visualization should respond in < 100ms to maintain the illusion of real-time operation."}),"\n",(0,o.jsx)(n.h3,{id:"optimization-techniques",children:"Optimization Techniques"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Level of Detail (LOD)"}),": Use simpler models when the camera is far away"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Occlusion Culling"}),": Don't render objects not visible to the camera"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Static Batching"}),": Combine static objects to reduce draw calls"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Dynamic Batching"}),": Unity automatically batches small dynamic objects"]}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-csharp",children:'// Performance monitoring script\nusing UnityEngine;\n\npublic class PerformanceMonitor : MonoBehaviour\n{\n    private float[] frameTimes = new float[60];\n    private int frameIndex = 0;\n\n    void Update()\n    {\n        frameTimes[frameIndex] = Time.unscaledDeltaTime;\n        frameIndex = (frameIndex + 1) % frameTimes.Length;\n\n        // Check if we\'re meeting the < 100ms response requirement\n        if (frameTimes[frameIndex] > 0.1f) // 100ms threshold\n        {\n            Debug.LogWarning("Frame time exceeded 100ms: " + frameTimes[frameIndex]);\n        }\n    }\n\n    public float GetAverageFrameTime()\n    {\n        float sum = 0;\n        for (int i = 0; i < frameTimes.Length; i++)\n        {\n            sum += frameTimes[i];\n        }\n        return sum / frameTimes.Length;\n    }\n\n    public int GetFps()\n    {\n        return Mathf.RoundToInt(1.0f / GetAverageFrameTime());\n    }\n}\n'})}),"\n",(0,o.jsx)(n.h2,{id:"exercise-6-interactive-elements",children:"Exercise 6: Interactive Elements"}),"\n",(0,o.jsx)(n.p,{children:"Digital twin visualizations often need interactive elements for user engagement."}),"\n",(0,o.jsx)(n.h3,{id:"adding-interaction",children:"Adding Interaction"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Camera Control"}),": Allow users to move around the environment"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Robot Control"}),": Allow users to control the robot in simulation"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Information Display"}),": Show robot state, sensor readings, etc."]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Simulation Controls"}),": Play, pause, reset simulation"]}),"\n"]}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-csharp",children:'// Camera controller for user interaction\nusing UnityEngine;\n\npublic class CameraController : MonoBehaviour\n{\n    public float moveSpeed = 5f;\n    public float lookSensitivity = 2f;\n\n    private float rotationX = 0f;\n    private float rotationY = 0f;\n\n    void Update()\n    {\n        // WASD for movement\n        float moveX = Input.GetAxis("Horizontal") * moveSpeed * Time.deltaTime;\n        float moveZ = Input.GetAxis("Vertical") * moveSpeed * Time.deltaTime;\n\n        // Handle rotation\n        if (Input.GetMouseButton(1)) // Right mouse button\n        {\n            rotationX += Input.GetAxis("Mouse X") * lookSensitivity;\n            rotationY -= Input.GetAxis("Mouse Y") * lookSensitivity;\n            rotationY = Mathf.Clamp(rotationY, -90f, 90f);\n\n            transform.localRotation = Quaternion.AngleAxis(rotationX, Vector3.up);\n            transform.localRotation *= Quaternion.AngleAxis(rotationY, Vector3.left);\n        }\n\n        // Move in the direction the camera is facing\n        Vector3 forward = transform.TransformDirection(Vector3.forward);\n        Vector3 right = transform.TransformDirection(Vector3.right);\n\n        transform.position += (forward * moveZ + right * moveX);\n    }\n}\n'})}),"\n",(0,o.jsx)(n.h2,{id:"validation-testing-your-unity-visualization",children:"Validation: Testing Your Unity Visualization"}),"\n",(0,o.jsx)(n.p,{children:"To validate that your Unity visualization is working correctly:"}),"\n",(0,o.jsxs)(n.ol,{children:["\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Visual Consistency"}),": Verify that Unity models match Gazebo physics models"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Synchronization"}),": Check that robot movements in Unity match physics simulation"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Performance"}),": Ensure frame rate stays above 30 FPS and response time < 100ms"]}),"\n",(0,o.jsxs)(n.li,{children:[(0,o.jsx)(n.strong,{children:"Coordinate Alignment"}),": Confirm that positions and orientations match between systems"]}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"Run the following validation steps:"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{className:"language-bash",children:"# Performance test - monitor Unity frame rate\n# Check that visualization updates respond to physics changes in < 100ms\n# Verify coordinate system conversions are correct\n# Test interaction elements work as expected\n"})}),"\n",(0,o.jsx)(n.h2,{id:"troubleshooting-common-unity-issues",children:"Troubleshooting Common Unity Issues"}),"\n",(0,o.jsx)(n.h3,{id:"visualization-doesnt-match-physics",children:"Visualization Doesn't Match Physics"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Check coordinate system conversions between ROS and Unity"}),"\n",(0,o.jsx)(n.li,{children:"Verify that visual models match URDF dimensions"}),"\n",(0,o.jsx)(n.li,{children:"Ensure joint angles are applied correctly"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"poor-performance",children:"Poor Performance"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Simplify meshes and reduce polygon count"}),"\n",(0,o.jsx)(n.li,{children:"Use Level of Detail (LOD) for complex models"}),"\n",(0,o.jsx)(n.li,{children:"Check for unnecessary update loops in scripts"}),"\n",(0,o.jsx)(n.li,{children:"Monitor draw calls and batching"}),"\n"]}),"\n",(0,o.jsx)(n.h3,{id:"synchronization-problems",children:"Synchronization Problems"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"Verify ROS connection is stable"}),"\n",(0,o.jsx)(n.li,{children:"Check that message frequencies match expectations"}),"\n",(0,o.jsx)(n.li,{children:"Confirm time synchronization between systems"}),"\n",(0,o.jsx)(n.li,{children:"Test network latency if systems are on different machines"}),"\n"]}),"\n",(0,o.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,o.jsx)(n.p,{children:"In this chapter, you learned how to create compelling visual representations for your digital twin:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsx)(n.li,{children:"How to set up Unity projects for digital twin applications"}),"\n",(0,o.jsx)(n.li,{children:"How to create visual models that match physics simulations"}),"\n",(0,o.jsx)(n.li,{children:"How to implement real-time synchronization between Gazebo and Unity"}),"\n",(0,o.jsx)(n.li,{children:"How to optimize performance to meet the < 100ms response requirement"}),"\n",(0,o.jsx)(n.li,{children:"How to add interactive elements for user engagement"}),"\n"]}),"\n",(0,o.jsx)(n.p,{children:"The visualization component completes the core digital twin concept by providing the visual representation that users interact with. In the next chapter, we'll explore sensor simulation to complete the perception pipeline of our digital twin."}),"\n",(0,o.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,o.jsx)(n.p,{children:"Continue to Chapter 3: Sensor Simulation and Integration to learn how to simulate various sensors (LiDAR, Depth Cameras, IMUs) that provide environmental awareness for your digital twin."})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>a});var t=i(6540);const o={},s=t.createContext(o);function r(e){const n=t.useContext(s);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),t.createElement(s.Provider,{value:n},e.children)}}}]);